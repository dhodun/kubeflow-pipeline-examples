{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS=\"./user-gcp-sa.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user google-cloud-automl==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install --user kfp --upgrade\n",
    "#! pip3 install --user google-cloud-automl"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "client = kfp.Client(host='4709991555f6b0ae-dot-us-central1.notebooks.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Serverless ML (Taxi) on KFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: set GCS location to experiment run\n",
    "TODO: set num passengers out of categorical\n",
    "TODO: run on unsampled datset\n",
    "TODO: set split column to use fingerprint\n",
    "TODO: Difference between table and dataset?\n",
    "TODO: try using a cleanup task with boolean in testing mode\n",
    "TODO: does generatinge new stats do anything?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "PROJECT_ID = 'dhodun1'\n",
    "COMPUTE_REGION = 'us-central1' # Currently us-central1 is only region\n",
    "BUCKET = 'dhodun1-central1'\n",
    "\n",
    "# Raw dataset, not cleaned\n",
    "QUERY = '''\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers\n",
    "FROM `nyc-tlc.yellow.trips`\n",
    "WHERE MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 100000) = 1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Tables components\n",
    "! git clone https://github.com/kubeflow/pipelines.git\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import components\n",
    "\n",
    "component_store = components.ComponentStore(local_search_paths=['./pipelines/components'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_create_dataset_for_tables_op = component_store.load_component('gcp/automl/create_dataset_for_tables')\n",
    "automl_import_data_from_bigquery_op = component_store.load_component('gcp/automl/import_data_from_bigquery')\n",
    "automl_import_data_from_gcs_op = component_store.load_component('gcp/automl/import_data_from_gcs')\n",
    "automl_create_model_for_tables_op = component_store.load_component('gcp/automl/create_model_for_tables')\n",
    "prediction_service_batch_predict_op = component_store.load_component('gcp/automl/prediction_service_batch_predict')\n",
    "automl_split_dataset_table_column_names_op = component_store.load_component('gcp/automl/split_dataset_table_column_names')\n",
    "\n",
    "bigquery_query_op = component_store.load_component('gcp/bigquery/query')\n",
    "#automl_create_dataset_for_tables_op = comp.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/b3179d86b239a08bf4884b50dbf3a9151da96d66/components/gcp/automl/create_dataset_for_tables/component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl_create_dataset_for_tables_op(PROJECT_ID, COMPUTE_REGION, 'taxi_data',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Op to change 'passengers' from categorical to numeric\n",
    "Should be fixed with *1.0 in BQ Query, but related to this BQ CSV export bug: https://b.corp.google.com/issues/143356550"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'projects/978546835329/locations/us-central1/datasets/TBL5712864505831096320'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def set_automl_tables_column_type(\n",
    "    dataset_path: str,\n",
    "    column_display_name: str,\n",
    "    type_code: str,    \n",
    "):\n",
    "    # Updates AutuML Column with new column type, does trigger a new column statistics job? how do we check?\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-automl==0.9.0', '--quiet', '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'}, check=True)\n",
    "    \n",
    "    from google.cloud import automl_v1beta1\n",
    "    client = automl_v1beta1.TablesClient()\n",
    "    \n",
    "    dataset = client.get_dataset(dataset_name=dataset_path)\n",
    "    \n",
    "    column_specs_response = client.list_column_specs(dataset=dataset)\n",
    "    column_specs = list(column_specs_response)\n",
    "    \n",
    "    for column in column_specs:\n",
    "        if column.display_name == column_display_name:\n",
    "            # This kicks off a new statistics job... how to check to see if it's done? Took ~ 1 minute this time\n",
    "            response = client.update_column_spec(column_spec_name=column.name, dataset=dataset, type_code=type_code)\n",
    "            print('Updated column: {} to type code {}. Generating new statistics now...'.format(column_display_name, type_code))\n",
    "\n",
    "set_automl_tables_column_type_op = components.func_to_container_op(set_automl_tables_column_type, base_image='python:3.7')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_automl_tables_column_type(dataset_path=dataset_path, column_display_name='passengers', type_code='FLOAT64')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "\n",
    "def serverless_automl(\n",
    "    gcp_project_id: str,\n",
    "    gcp_region: str,\n",
    "    query: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_temp_directory: str = 'ml-taxi/{}'.format(dsl.RUN_ID_PLACEHOLDER),\n",
    "    dataset_display_name: str = 'taxi_data',\n",
    "    dataset_location: str = 'US',\n",
    "    target_column_name: str = 'fare_amount',\n",
    "    model_display_name: str = 'taxi_data_model',\n",
    "    train_budget_milli_node_hours: 'Integer' = 1000,\n",
    "):\n",
    "    \n",
    "    output_gcs_path='gs://{}/{}/bq_taxi_output.csv'.format(gcs_bucket, gcs_temp_directory)\n",
    "    '''\n",
    "    # Create dataset\n",
    "    create_dataset_task = automl_create_dataset_for_tables_op(\n",
    "        gcp_project_id=gcp_project_id,\n",
    "        gcp_region=gcp_region,\n",
    "        display_name=dataset_display_name,\n",
    "    )\n",
    "    \n",
    "    # Query to clean dataset and dump to GCS\n",
    "    bigquery_export_task = bigquery_query_op(\n",
    "        query=query,\n",
    "        project_id=gcp_project_id,\n",
    "        output_gcs_path=output_gcs_path,\n",
    "        dataset_location=dataset_location,\n",
    "    )\n",
    "    \n",
    "    # Import data from GCS automl_import_data_from_gcs_op\n",
    "    import_data_task = automl_import_data_from_gcs_op(\n",
    "        dataset_path=create_dataset_task.outputs['dataset_path'],\n",
    "        input_uris=[output_gcs_path],\n",
    "    ).after(bigquery_export_task)\n",
    "    '''\n",
    "    # Prepare column schemas\n",
    "    split_column_specs_task = automl_split_dataset_table_column_names_op(\n",
    "        #dataset_path=import_data_task.outputs['dataset_path'],\n",
    "        dataset_path='projects/978546835329/locations/us-central1/datasets/TBL5712864505831096320',\n",
    "        table_index=0,\n",
    "        target_column_name=target_column_name,        \n",
    "    )\n",
    "    \n",
    "    # Train a model\n",
    "    create_model_task = automl_create_model_for_tables_op(\n",
    "        gcp_project_id=gcp_project_id,\n",
    "        gcp_region=gcp_region,\n",
    "        display_name=model_display_name,\n",
    "        #dataset_id=create_dataset_task.outputs['dataset_id'],\n",
    "        dataset_id='TBL5712864505831096320',\n",
    "        target_column_path=split_column_specs_task.outputs['target_column_path'],\n",
    "        #input_feature_column_paths=None, # All non-target columns will be used if None is passed\n",
    "        input_feature_column_paths=split_column_specs_task.outputs['feature_column_paths'],\n",
    "        optimization_objective='MINIMIZE_RMSE',\n",
    "        train_budget_milli_node_hours=train_budget_milli_node_hours,\n",
    "    )\n",
    "    \n",
    "    from kfp.gcp import use_gcp_secret\n",
    "    kfp.dsl.get_pipeline_conf().add_op_transformer(use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "\n",
    "from google.cloud import automl\n",
    "\n",
    "#location_path = automl.AutoMlClient().location_path(PROJECT_ID, COMPUTE_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host='4709991555f6b0ae-dot-us-central1.notebooks.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import automl\n",
    "\n",
    "#PROJECT_ID = 'dhodun1'\n",
    "#COMPUTE_REGION = 'us-central1' # Currently us-central1 is only region\n",
    "\n",
    "#location_path = automl.AutoMlClient().location_path(PROJECT_ID, COMPUTE_REGION)\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    serverless_ml_taxi_pipeline,\n",
    "    arguments=dict(\n",
    "        gcp_project_id=PROJECT_ID,\n",
    "        gcp_region=COMPUTE_REGION,\n",
    "        query=QUERY,\n",
    "        gcs_bucket=BUCKET,\n",
    "        dataset_display_name='taxi_data',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud container clusters list"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud container clusters get-credentials kubeflow-marketplace-1 --zone us-central1-a"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'projects/978546835329/locations/us-central1/datasets/TBL5712864505831096320'\n",
    "client = automl.AutoMlClient()\n",
    "list_table_specs_response = client.list_table_specs(dataset_path)\n",
    "list_table_specs_response\n",
    "table_specs = [s for s in list_table_specs_response]\n",
    "print('table_specs=')\n",
    "print(table_specs)\n",
    "table_spec_name = table_specs[0].name\n",
    "\n",
    "list_column_specs_response = client.list_column_specs(table_spec_name)\n",
    "column_specs = [s for s in list_column_specs_response]\n",
    "#client.get_column_spec('passengers')\n",
    "for column in column_specs:\n",
    "    if column.display_name == 'passengers':\n",
    "        passenger_column = column.name\n",
    "\n",
    "print('column_specs=')\n",
    "#print(column_specs)\n",
    "\n",
    "column = client.get_column_spec(passenger_column)\n",
    "print(column)\n",
    "\n",
    "#client = automl_v1beta1.TablesClient()\n",
    "\n",
    "client.update_column_spec(column_spec_name=passenger_column, type_code='NUMERIC')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "column.name"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_specs[]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.run_pipeline_func_on_cluster(\n",
    "    serverless_ml_taxi_pipeline,\n",
    "    arguments = dict(\n",
    "        gcp_project_id=PROJECT_ID,\n",
    "        gcp_region=COMPUTE_REGION,\n",
    "        display_name='taxi_data'\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}